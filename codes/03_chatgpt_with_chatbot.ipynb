{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from openai import OpenAI, AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI(\n",
    "#   api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add context to maintain conversation continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_messages(messages: list[dict]):\n",
    "    try:\n",
    "        with open('./db.dat', 'wb') as f:\n",
    "            db = {'data': messages}\n",
    "            pickle.dump(db, f)\n",
    "    except:\n",
    "        print('Failed to save messages.')\n",
    "\n",
    "\n",
    "def load_messages() -> list[dict]:\n",
    "    try:\n",
    "        with open('./db.dat', 'rb') as f:\n",
    "            db = pickle.load(f)\n",
    "            return db.get('data', [])\n",
    "    except:\n",
    "        print('Failed to load messages.')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "# messages = load_messages()\n",
    "\n",
    "system_prompt = \"請扮演一位智能助理，記住我告訴過你的資訊。\"\n",
    "messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "print(f'System: {system_prompt}')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_prompt = input(\"User: \")\n",
    "        if not user_prompt.strip():\n",
    "            break\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        print(f'User: {user_prompt}')\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-35-turbo-120\",\n",
    "            messages=messages\n",
    "        )\n",
    "        assistant_prompt = completion.choices[0].message.content\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_prompt})\n",
    "        print(f'ChatGPT: {assistant_prompt}')\n",
    "\n",
    "    except openai.APIError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "        break\n",
    "\n",
    "# save_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Chatbot with Gradio\n",
    "Reference: https://www.gradio.app/guides/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(message, history, system_prompt, stream, temperature):\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    for user_prompt, assistant_prompt in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-120\",\n",
    "        messages=messages,\n",
    "        stream=stream,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    if stream:\n",
    "        response = ''\n",
    "        for chunk_completion in completion:\n",
    "            if chunk_completion.choices:\n",
    "                response += chunk_completion.choices[0].delta.content or ''\n",
    "                yield response\n",
    "    else:\n",
    "        response = completion.choices[0].message.content\n",
    "        yield response\n",
    "\n",
    "\n",
    "app = gr.ChatInterface(\n",
    "    get_response,\n",
    "    additional_inputs=[\n",
    "        # Reference: https://www.gradio.app/guides/creating-a-chatbot-fast#additional-inputs\n",
    "        gr.Textbox(\"You are helpful AI.\", label=\"System Prompt\"),\n",
    "        gr.Checkbox(label='Stream', value=True),\n",
    "        gr.Slider(0, 2, value=0.8, label=\"Temperature\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "app.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "練習：製作一個「多國語言翻譯」的聊天機器人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(message, history, language, stream, temperature):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-120\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f'請將使用者的輸入翻譯成 {language} 且文法正確'},\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "        ],\n",
    "        stream=stream,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    if stream:\n",
    "        response = ''\n",
    "        for chunk_completion in completion:\n",
    "            if chunk_completion.choices:\n",
    "                response += chunk_completion.choices[0].delta.content or ''\n",
    "                yield response\n",
    "    else:\n",
    "        response = completion.choices[0].message.content\n",
    "        yield response\n",
    "\n",
    "\n",
    "app = gr.ChatInterface(\n",
    "    get_response,\n",
    "    additional_inputs=[\n",
    "        gr.Textbox(\"english\", label=\"Language\"),\n",
    "        gr.Checkbox(label='Stream', value=True),\n",
    "        gr.Slider(0, 2, value=0.8, label=\"Temperature\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "app.queue().launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Chatbot with LINE in Replit\n",
    "\n",
    "Reference: \n",
    "- https://developers.line.biz/console/\n",
    "- https://github.com/line/line-bot-sdk-python/blob/master/examples/flask-echo/app_with_handler.py\n",
    "- https://replit.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from flask import Flask, request, abort\n",
    "\n",
    "from linebot.v3 import WebhookHandler\n",
    "from linebot.v3.exceptions import InvalidSignatureError\n",
    "from linebot.v3.messaging import Configuration, ApiClient, MessagingApi, ReplyMessageRequest, TextMessage\n",
    "from linebot.v3.webhooks import MessageEvent, TextMessageContent\n",
    "\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "configuration = Configuration(\n",
    "    access_token=os.getenv('LINE_CHANNEL_ACCESS_TOKEN')\n",
    ")\n",
    "handler = WebhookHandler(os.getenv('LINE_CHANNEL_SECRET'))\n",
    "\n",
    "# client = OpenAI(\n",
    "#   api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "def index():\n",
    "    return 'Server is running!'\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=['POST'])\n",
    "def callback():\n",
    "    # get X-Line-Signature header value\n",
    "    signature = request.headers['X-Line-Signature']\n",
    "\n",
    "    # get request body as text\n",
    "    body = request.get_data(as_text=True)\n",
    "    app.logger.info(\"Request body: \" + body)\n",
    "\n",
    "    # handle webhook body\n",
    "    try:\n",
    "        handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        app.logger.info(\"Invalid signature. Please check your channel access token / channel secret.\")\n",
    "        abort(400)\n",
    "\n",
    "    return 'OK'\n",
    "\n",
    "\n",
    "def get_chatgpt_response(user_prompt: str) -> str:\n",
    "    system_prompt = \"請扮演使用者的愛人，並用少女的方式回答使用者的問題。\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-120\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response\n",
    "\n",
    "\n",
    "@handler.add(MessageEvent, message=TextMessageContent)\n",
    "def message_text(event):\n",
    "    print('========== Received a message. ==========')\n",
    "    print(f'::Event:: {event}')\n",
    "\n",
    "    print('========== Send a message. ==========')\n",
    "    print(f'::UserID:: {event.source.user_id}')\n",
    "    user_prompt = event.message.text.strip()\n",
    "    print(f'::User:: {user_prompt}')\n",
    "    chatgpt_response = get_chatgpt_response(user_prompt)\n",
    "    print(f'::ChatGPT:: {chatgpt_response}')\n",
    "\n",
    "    with ApiClient(configuration) as api_client:\n",
    "        line_bot_api = MessagingApi(api_client)\n",
    "        line_bot_api.reply_message_with_http_info(\n",
    "            ReplyMessageRequest(\n",
    "                reply_token=event.reply_token,\n",
    "                messages=[TextMessage(text=chatgpt_response)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
