{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "from rich import print as pprint\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Construct an instance of OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI(\n",
    "#   api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "# )\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Making an API request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 請推薦我今天午餐要吃什麼？\n",
      "Completion: 士子：蒙吾尊詢，午膳之事，實為小生恐難為之也。蓋今天世事繁衍，網羅萬象，各種美食均可供應。君欲何種菜餚或飲食之物？方可明智布置。舉凡糙米飯、湯羹品、蔬菜果品、肉魚蛋類，皆為膳食之佳選。休者之間，亦可杯羹小酌，以添娛樂之意。\n",
      "\n",
      "然衣食住行，各有所好。捷足先登者或有所雅好，倘欲嘗鮮新潮，若差一些不是風尚者，亦未可知。但願君斟酌良久，懷思遐情，方可作出最佳選擇。\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"請你用文言文的方式回答使用者的問題。\"\n",
    "user_prompt = \"請推薦我今天午餐要吃什麼？\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-35-turbo-120\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(f'Prompt: {user_prompt}')\n",
    "print(f'Completion: {completion.choices[0].message.content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-9nM9VEiB18F0Hxl3R7NY43tIPyUDY'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'士子：蒙吾尊詢，午膳之事，實為小生恐難為之也。蓋今天世事繁衍，網羅萬象，各種美食均可供應。</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">君欲何種菜餚或飲食之物？方可明智布置。舉凡糙米飯、湯羹品、蔬菜果品、肉魚蛋類，皆為膳食之佳選。休者之間，亦可杯羹小</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">酌，以添娛樂之意。\\n\\n然衣食住行，各有所好。捷足先登者或有所雅好，倘欲嘗鮮新潮，若差一些不是風尚者，亦未可知。但願</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">君斟酌良久，懷思遐情，方可作出最佳選擇。'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">content_filter_results</span>=<span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'hate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'self_harm'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'sexual'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'violence'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1721550253</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-35-turbo'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">283</span>, <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span>, <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">337</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">prompt_filter_results</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content_filter_results'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'hate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'self_harm'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'sexual'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'violence'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-9nM9VEiB18F0Hxl3R7NY43tIPyUDY'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'士子：蒙吾尊詢，午膳之事，實為小生恐難為之也。蓋今天世事繁衍，網羅萬象，各種美食均可供應。\u001b[0m\n",
       "\u001b[32m君欲何種菜餚或飲食之物？方可明智布置。舉凡糙米飯、湯羹品、蔬菜果品、肉魚蛋類，皆為膳食之佳選。休者之間，亦可杯羹小\u001b[0m\n",
       "\u001b[32m酌，以添娛樂之意。\\n\\n然衣食住行，各有所好。捷足先登者或有所雅好，倘欲嘗鮮新潮，若差一些不是風尚者，亦未可知。但願\u001b[0m\n",
       "\u001b[32m君斟酌良久，懷思遐情，方可作出最佳選擇。'\u001b[0m,\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mcontent_filter_results\u001b[0m=\u001b[1m{\u001b[0m\n",
       "                \u001b[32m'hate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'severity'\u001b[0m: \u001b[32m'safe'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'self_harm'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'severity'\u001b[0m: \u001b[32m'safe'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'sexual'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'severity'\u001b[0m: \u001b[32m'safe'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'violence'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'severity'\u001b[0m: \u001b[32m'safe'\u001b[0m\u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1721550253\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-35-turbo'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m283\u001b[0m, \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m54\u001b[0m, \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m337\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mprompt_filter_results\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'prompt_index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m'content_filter_results'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'hate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'severity'\u001b[0m: \u001b[32m'safe'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'self_harm'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'severity'\u001b[0m: \u001b[32m'safe'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'sexual'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'severity'\u001b[0m: \u001b[32m'safe'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'violence'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'filtered'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'severity'\u001b[0m: \u001b[32m'safe'\u001b[0m\u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rich text and beautiful formatting in the terminal.\n",
    "pprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token\n",
    "- Token 通常指的是文字處理過程中的最小單位。 \n",
    "- Token 是模型視角中的單字，可以是字符、詞語、片語、句子或其他較小的文字單元，取決於模型的設計。\n",
    "- Tokenization 是將一段連續的文字序列拆分為 Token 的過程。\n",
    "\n",
    "- Embedding 是將離散的文字資料轉換為連續的、低維度向量。\n",
    "- Embedding 是把人類的語言轉換成電腦看得懂的語言或意思。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.encoding_for_model('gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人類視角看到的文字：我愛你\n",
      "模型視角看到的向量：[37046, 31374, 249, 57668]\n",
      "---\n",
      "人類視角看到的文字：我喜歡你\n",
      "模型視角看到的向量：[37046, 83601, 250, 15722, 94, 57668]\n"
     ]
    }
   ],
   "source": [
    "encoder = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "\n",
    "tokens = encoder.encode('我愛你')\n",
    "print(f'人類視角看到的文字：{encoder.decode(tokens)}')\n",
    "print(f'模型視角看到的向量：{tokens}')\n",
    "print('---')\n",
    "\n",
    "tokens = encoder.encode('我喜歡你')\n",
    "print(f'人類視角看到的文字：{encoder.decode(tokens)}')\n",
    "print(f'模型視角看到的向量：{tokens}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: 為什麼使用 ChatGPT API 跟用 TikToken Encoder 計算出來的 token 數量會不一樣呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT Token count: 54\n",
      "TikToken Token count: 43\n"
     ]
    }
   ],
   "source": [
    "token_count = completion.usage.prompt_tokens\n",
    "print(f'ChatGPT Token count: {token_count}')\n",
    "\n",
    "encoder = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "token_count = len(encoder.encode(system_prompt+user_prompt))\n",
    "print(f'TikToken Token count: {token_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A: 因為 prompt 的 Chat Markup Language (ChatML) 也要納入 token 數量的計算。\n",
    "\n",
    "當 messages 輸入 ...\n",
    "``` \n",
    "[\n",
    "    {\"role\": \"system\", \"content\": system_prompt_content},\n",
    "    {\"role\": \"user\", \"content\": user_prompt_content}\n",
    "]\n",
    "```\n",
    "等同於 ...\n",
    "```\n",
    "<|im_start|>system\\n{system_prompt_content}<|im_end|>   => 4 個 token 數\n",
    "<|im_start|>user\\n{user_prompt_content}<|im_end|>       => 4 個 token 數\n",
    "<|im_start|>assistant<|message|>                        => 3 個 token 數\n",
    "```\n",
    "因此需要額外再加 11 個 token 數。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT API 參數使用與說明\n",
    "\n",
    "- `n`: 控制 completion 輸出的數量\n",
    "\n",
    "+ `max_tokens`: 控制 completion 的 token 最大上限，預設為模型上下文的最大長度\n",
    "    - 輸入值值不可以超過 model 回傳輸出的上限（context_length_exceeded）\n",
    "    - `finish_reason=length`，表示 completion 長度被限制而終止\n",
    "    - `finish_reason=stop`，表示 completion 正常結束\n",
    "\n",
    "- `temperature`: 控制 completion 的變化比重/隨機性，介於 0 到 2 之間，預設為 1\n",
    "    - `temperature=0`，表示隨機性最低 = 回傳機率最高的下一個字\n",
    "    - `temperature=1.5`，表示隨機性介於中間\n",
    "    - `temperature=2`，表示隨機性最高，但會跑很久，不建議這樣設置\n",
    "    - `seed`\n",
    "\n",
    "+ `logit`: 控制 completion 的權重\n",
    "    - `logit_bias`: 介於 -100(絕對不要出現) 到 100(絕對要出現) 之間，盡可能約束模型，但不能 100％ 控制\n",
    "    - `logprobs`\n",
    "    - `top_logprobs`\n",
    "\n",
    "- `penalty`: 懲罰項，用以控制詞彙的重複性\n",
    "    - `top_p`: 控制 completion 的變化比重，和 `temperature` 擇一使用，預設為 1\n",
    "        - `top_p=0`，回傳最高的可能性，等價於 `temperature=0` 的效果\n",
    "        - `top_p=1`，增加隨機性，等價於 `temperature=1` 的效果  \n",
    "    - `presence_penalty`: 介於 -2 到 2 之間，預設為 0\n",
    "        - `presence_penalty=2`，表示盡可能不出現重複的字詞\n",
    "        - `presence_penalty=-2`，表示盡可能出現重複的字詞\n",
    "    - `frequency_penalty`: 介於 -2 到 2 之間，預設為 0\n",
    "        - 和 `presence_penalty` 作用一樣，只是算法不一樣\n",
    "\n",
    "+ `response_format`: 指定 completion 回傳格式\n",
    "    - `response_format={'type': 'text'}`\n",
    "    - `response_format={'type': 'json_object'}`，需要在 system_prompt 寫 “請用 json 格式回覆”，此功能才會 work\n",
    "\n",
    "Reference: https://platform.openai.com/docs/api-reference/chat/create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7305, 122, 37046, 57668, 43511]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "encoder.encode('吾我你他')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "建議: 請用文言文的方式回答使用者的問題\n",
      "問題: 你好～我叫黃小豬，是女生，請問你吃飽了嗎？\n",
      "實際使用的模型: gpt-35-turbo\n",
      "總共使用的 Token 數: 376 = 59 (問題) + 317 (回覆)\n",
      "==============================\n",
      "回覆 1: 恭敬問候黃小豬女士，卑職已經用膳過了，謝謝您的關心。敢問女士飲食是否安排妥當？\n",
      "回覆 1 終止的原因: stop\n",
      "------------------------------\n",
      "回覆 2: 黃小豬小姐，您好！臣妾衷心感謝您的關心，但是作為一個語言模型AI，臣妾無法進食，亦無需進食，只有為您提供文字上的協助和回答問題的能力。若有其他問題，請隨時提出，臣妾將竭誠為您服務。\n",
      "回覆 2 終止的原因: stop\n",
      "------------------------------\n",
      "回覆 3: None\n",
      "回覆 3 終止的原因: content_filter\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"請用文言文的方式回答使用者的問題\"\n",
    "user_prompt = \"你好～我叫黃小豬，是女生，請問你吃飽了嗎？\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-35-turbo-120\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ],\n",
    "  n=3,\n",
    "  # max_tokens=40,\n",
    "  # temperature=1.5,\n",
    "  # seed=1,\n",
    "  # logit_bias={7305: -100, 122: -100, 37046: -100, 57668: -100, 43511: -100},\n",
    "  # top_p=0,\n",
    "  # presence_penalty=2,\n",
    "  # response_format={'type': 'json_object'},\n",
    ")\n",
    "\n",
    "print(f'建議: {system_prompt}')\n",
    "print(f'問題: {user_prompt}')\n",
    "print(f'實際使用的模型: {completion.model}')\n",
    "print(f'總共使用的 Token 數: {completion.usage.total_tokens} = {completion.usage.prompt_tokens} (問題) + {completion.usage.completion_tokens} (回覆)')\n",
    "print('='* 30 )\n",
    "for i, choice in enumerate(completion.choices):\n",
    "    print(f'回覆 {i+1}: {choice.message.content}')\n",
    "    print(f'回覆 {i+1} 終止的原因: {choice.finish_reason}')\n",
    "    print('-' * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
